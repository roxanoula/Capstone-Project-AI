{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the mnist dataset from keras\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load dataset\n",
    "def load_mnist_dataset():\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    # reshape dataset to have a single channel (1 color)\n",
    "    train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "    test_images  = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "    \n",
    "    # convert the vector trainY and testY in a one hot encoding (an array of 0s and 1)\n",
    "    train_labels = to_categorical(train_labels, num_classes=None, dtype='float32')\n",
    "    test_labels = to_categorical(test_labels, num_classes=None, dtype='float32')\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# summarize loaded dataset\n",
    "def summarize_mnist_dataset(trainX, trainY, testX, testY): \n",
    "    print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
    "    print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
    "\n",
    "    # plot first few images\n",
    "    for i in range(9):\n",
    "        # define subplot\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
    "\n",
    "    # show the figure\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_mnist_dataset()\n",
    "summarize_mnist_dataset(train_images, train_labels, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # Modifying the values of each pixel such that they range from 0 to 1 will improve the rate at which our model learns.\n",
    "    train = train.reshape(train.shape[0], 28*28)\n",
    "    test = test.reshape(test.shape[0], 28*28)\n",
    "   \n",
    "    #convert into to float\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#define simple NN model\n",
    "def simple_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(8, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def simple_model_2_layers():\n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(8, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    model.add(Dense(8, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def simple_model_more_nodes():\n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(784, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    train_norm, test_norm = prep_pixels(train_images, test_images)\n",
    "    \n",
    "    model.fit(train_norm, train_labels, epochs=5, batch_size=128)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_norm, test_labels)\n",
    "    print('test_acc:', test_acc, 'test_loss', test_loss)\n",
    "    \n",
    "    train_loss, train_acc = model.evaluate(train_norm, train_labels)\n",
    "    print('train_acc:', train_acc, 'train_loss', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lets evaluate the model\")\n",
    "simple_model = simple_model()\n",
    "evaluate_model(simple_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Description*: We can increase the accuracy for this model if we increase the number activation nodes. The accuracy is pretty low comparing with other models that exists for this dataset.\n",
    "*Input*: Use 784 activation nodes for hidden later\n",
    "         The accuracy should increase because the model has more `detailed`. More activation nodes will allow the recording of more features that, in turn, will help algorithm distinguish better the shapes.\n",
    "*Output*: The accuracy improved from .88 to .91\n",
    "        The result is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_more_nodes = simple_model_more_nodes()\n",
    "evaluate_model(model_more_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*Description*: We can increase the accuracy for this model if we increase the number of hidden layers. The accuracy is pretty low comparing with other models that exists for this dataset.\n",
    "*Input*: Use 4 activation nodes in the hidden later\n",
    "         The accuracy should increase because the model is more complex and it has more layers to compute the correct prediction\n",
    "*Output*: The accuracy decreese from .88 to .84\n",
    "          The result is different than expected.\n",
    "          A possible explanation is that the input dataset is relativelly small and with added layer we add more parameters to learn but we do not have enough data for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_layers = simple_model_2_layers()\n",
    "evaluate_model(model_2_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
